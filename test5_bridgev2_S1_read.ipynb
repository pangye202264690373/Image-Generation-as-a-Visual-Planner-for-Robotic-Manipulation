{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4cfe917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ==== 参数设置 ====\n",
    "builder_dir = r\"E:\\bridgev2\\0.1.0\"      # TFDS 数据目录（含 dataset_info.json / features.json / tfrecord-*）\n",
    "# split       = \"train\"\n",
    "# frame_indices = [0]                 # [0]=第一帧；[-1]=最后一帧；[0, -1]=第一+最后；None=全部帧\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "176a9b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name: bridge\n",
      "Dataset Version: 0.1.0\n",
      "Dataset Homepage: https://rail-berkeley.github.io/bridgedata/\n",
      "Dataset Description: WidowX interacting with toy kitchens\n",
      "\n",
      "Splits Information:\n",
      "train: 25460 examples, 365,981,955,835 bytes\n",
      "test: 3475 examples, 50,084,717,377 bytes\n",
      "\n",
      "Info:\n",
      "tfds.core.DatasetInfo(\n",
      "    name='bridge',\n",
      "    full_name='bridge/0.1.0',\n",
      "    description=\"\"\"\n",
      "    WidowX interacting with toy kitchens\n",
      "    \"\"\",\n",
      "    homepage='https://rail-berkeley.github.io/bridgedata/',\n",
      "    data_dir='E:\\\\bridgev2\\\\0.1.0',\n",
      "    file_format=tfrecord,\n",
      "    download_size=Unknown size,\n",
      "    dataset_size=387.49 GiB,\n",
      "    features=FeaturesDict({\n",
      "        'steps': Dataset({\n",
      "            'action': FeaturesDict({\n",
      "                'open_gripper': bool,\n",
      "                'rotation_delta': Tensor(shape=(3,), dtype=float32),\n",
      "                'terminate_episode': float32,\n",
      "                'world_vector': Tensor(shape=(3,), dtype=float32),\n",
      "            }),\n",
      "            'is_first': bool,\n",
      "            'is_last': bool,\n",
      "            'is_terminal': bool,\n",
      "            'observation': FeaturesDict({\n",
      "                'image': Image(shape=(480, 640, 3), dtype=uint8),\n",
      "                'natural_language_embedding': Tensor(shape=(512,), dtype=float32),\n",
      "                'natural_language_instruction': string,\n",
      "                'state': Tensor(shape=(7,), dtype=float32),\n",
      "            }),\n",
      "            'reward': Scalar(shape=(), dtype=float32),\n",
      "        }),\n",
      "    }),\n",
      "    supervised_keys=None,\n",
      "    disable_shuffling=False,\n",
      "    nondeterministic_order=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=3475, num_shards=512>,\n",
      "        'train': <SplitInfo num_examples=25460, num_shards=1024>,\n",
      "    },\n",
      "    citation=\"\"\"@inproceedings{walke2023bridgedata,\n",
      "        title={BridgeData V2: A Dataset for Robot Learning at Scale},\n",
      "        author={Walke, Homer and Black, Kevin and Lee, Abraham and Kim, Moo Jin and Du, Max and Zheng, Chongyi and Zhao, Tony and Hansen-Estruch, Philippe and Vuong, Quan and He, Andre and Myers, Vivek and Fang, Kuan and Finn, Chelsea and Levine, Sergey},\n",
      "        booktitle={Conference on Robot Learning (CoRL)},\n",
      "        year={2023}\n",
      "    }\"\"\",\n",
      ")\n",
      "\n",
      "Supervised Keys:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 使用 builder_from_directory 加载数据集\n",
    "builder = tfds.builder_from_directory(builder_dir)\n",
    "\n",
    "# 获取数据集的 info 信息\n",
    "info = builder.info\n",
    "\n",
    "# 打印数据集的基本信息\n",
    "print(\"Dataset Name:\", builder.name)\n",
    "print(\"Dataset Version:\", info.version)\n",
    "print(\"Dataset Homepage:\", info.homepage)\n",
    "print(\"Dataset Description:\", info.description)\n",
    "\n",
    "# 打印 splits 信息\n",
    "print(\"\\nSplits Information:\")\n",
    "for split, split_info in info.splits.items():\n",
    "    print(f\"{split}: {split_info.num_examples} examples, {split_info.num_bytes:,} bytes\")\n",
    "\n",
    "# 打印 features 信息\n",
    "print(\"\\nInfo:\")\n",
    "print(info)\n",
    "\n",
    "# 打印监督的键\n",
    "print(\"\\nSupervised Keys:\")\n",
    "print(info.supervised_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ebd9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = builder.as_dataset(split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e12fdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting samples:   0%|          | 0/3475 [00:08<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "max_to_check = 100000  # 防止太慢，可设大一点\n",
    "count = 0\n",
    "\n",
    "# 这里不再使用 ds[split]，因为 ds 已经是一个 Dataset 了\n",
    "for _ in tqdm(ds.take(max_to_check), desc=\"Counting samples\"):\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629213f5",
   "metadata": {},
   "source": [
    "## 分别提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712e8803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 输出准备 ====\n",
    "output_path  = r\"F:\\PangYe\\bridgev2_DATA\\extracted\" # 输出目录\n",
    "output_dir = Path(output_path)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "max_samples = 10                     # None 表示全部样本；设为整数表示只处理这么多\n",
    "\n",
    "# ==== 迭代样本 ====\n",
    "pbar = tqdm(enumerate(ds.take(max_samples), start=1), total=max_samples, desc=\"Extracting samples\")\n",
    "\n",
    "for sample_idx, example in pbar:\n",
    "    steps = example[\"steps\"]\n",
    "\n",
    "    # 创建当前 episode 文件夹：id00001, id00002, ...\n",
    "    ep_dir = output_dir / f\"id{sample_idx:05d}\"\n",
    "    images_dir = ep_dir / \"images\"\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    lang = None\n",
    "\n",
    "    # 遍历 step 并保存图片\n",
    "    for step_idx, step in enumerate(steps.as_numpy_iterator(), start=1):\n",
    "        img = step[\"observation\"][\"image\"]\n",
    "        lang_text = step[\"observation\"][\"natural_language_instruction\"].decode(\"utf-8\")\n",
    "\n",
    "        # 记录第一步的自然语言指令\n",
    "        if step_idx == 1:\n",
    "            lang = lang_text\n",
    "\n",
    "        # 保存图像到 images/ 目录\n",
    "        img_pil = Image.fromarray(img)\n",
    "        img_name = f\"step{step_idx:03d}.png\"\n",
    "        img_pil.save(images_dir / img_name)\n",
    "\n",
    "    # 保存语言到 instruction.txt（与 images 平级）\n",
    "    if lang is not None:\n",
    "        with open(ep_dir / \"instruction.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(lang.strip())\n",
    "\n",
    "pbar.close()\n",
    "print(f\"\\n✅ 提取完成，共保存 {min(max_samples, builder.info.splits[split].num_examples)} 个 episode。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ff27e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 输出准备 ====\n",
    "output_path  = r\"F:\\PangYe\\bridgev2_DATA\\extracted_1\" # 输出目录\n",
    "output_dir = Path(output_path)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "max_samples = 10                     # None 表示全部样本；设为整数表示只处理这么多\n",
    "\n",
    "# ==== 迭代样本 ====\n",
    "pbar = tqdm(enumerate(ds.take(max_samples), start=1), total=max_samples, desc=\"Extracting samples\")\n",
    "\n",
    "for sample_idx, example in pbar:\n",
    "    steps = example[\"steps\"]\n",
    "\n",
    "    # 创建当前 episode 文件夹：id00001, id00002, ...\n",
    "    ep_dir = output_dir / f\"id{sample_idx:05d}\"\n",
    "    ep_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # === 1. 记录首步语言指令 ===\n",
    "    lang = None\n",
    "\n",
    "    # === 2. 遍历 step 并保存图片 ===\n",
    "    for step_idx, step in enumerate(steps.as_numpy_iterator(), start=1):\n",
    "        img = step[\"observation\"][\"image\"]\n",
    "        lang_text = step[\"observation\"][\"natural_language_instruction\"].decode(\"utf-8\")\n",
    "\n",
    "        # 保存第一个 step 的语言\n",
    "        if step_idx == 1:\n",
    "            lang = lang_text\n",
    "\n",
    "        # 保存图像\n",
    "        img_pil = Image.fromarray(img)\n",
    "        img_name = f\"step{step_idx:03d}.png\"\n",
    "        img_pil.save(ep_dir / img_name)\n",
    "\n",
    "    # === 3. 保存语言到 txt 文件 ===\n",
    "    if lang is not None:\n",
    "        with open(ep_dir / \"instruction.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(lang.strip())\n",
    "\n",
    "pbar.close()\n",
    "print(f\"\\n✅ 提取完成，共保存 {min(max_samples, builder.info.splits[split].num_examples)} 个 episode。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01904eb",
   "metadata": {},
   "source": [
    "## 取九"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd67b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 迭代样本（使用 np.linspace 采样9帧，含首尾） ====\n",
    "output_path  = r\"F:\\PangYe\\bridgev2_DATA\\extracted_nine_train\" # 输出目录\n",
    "output_dir = Path(output_path)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "max_samples = 25460                     # None 表示全部样本；设为整数表示只处理这么多\n",
    "\n",
    "pbar = tqdm(enumerate(ds.take(max_samples), start=1), total=max_samples, desc=\"Extracting 9 frames (linspace)\")\n",
    "\n",
    "\n",
    "for sample_idx, example in pbar:\n",
    "    steps = list(example[\"steps\"].as_numpy_iterator())\n",
    "    num_steps = len(steps)\n",
    "\n",
    "    ep_dir = output_dir / f\"id{sample_idx:05d}\"\n",
    "    images_dir = ep_dir / \"images\"\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # === 1. 提取第一步语言指令 ===\n",
    "    lang = steps[0][\"observation\"][\"natural_language_instruction\"].decode(\"utf-8\")\n",
    "\n",
    "    # === 2. 计算9个等间隔索引（包含首帧与末帧） ===\n",
    "    if num_steps <= 9:\n",
    "        frame_indices = np.arange(num_steps)\n",
    "    else:\n",
    "        frame_indices = np.linspace(0, num_steps - 1, num=9, dtype=int)\n",
    "\n",
    "    # === 3. 保存这些帧 ===\n",
    "    for local_idx, step_idx in enumerate(frame_indices, start=1):\n",
    "        img = steps[step_idx][\"observation\"][\"image\"]\n",
    "        img_pil = Image.fromarray(img)\n",
    "        img_name = f\"step{step_idx:03d}.png\"\n",
    "        img_pil.save(images_dir / img_name)\n",
    "\n",
    "    # === 4. 保存语言文件 ===\n",
    "    with open(ep_dir / \"instruction.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(lang.strip())\n",
    "\n",
    "pbar.close()\n",
    "print(f\"\\n✅ 提取完成（每个 episode 使用 np.linspace 等间隔选取 9 帧，含首尾），共保存 {min(max_samples, builder.info.splits[split].num_examples)} 个 episode。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0700e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 配置 ====\n",
    "output_path  = r\"F:\\PangYe\\bridgev2_DATA\\extracted_nine_train\"\n",
    "output_dir = Path(output_path)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "MAX_SAMPLES = 20000   # None 表示不限制\n",
    "\n",
    "ID_RE = re.compile(r\"^id(\\d{5})$\")\n",
    "\n",
    "def is_episode_complete(ep_dir: Path) -> bool:\n",
    "    \"\"\"判断该 episode 是否完整（有 instruction.txt 且 images 里 >=9 张）\"\"\"\n",
    "    images_dir = ep_dir / \"images\"\n",
    "    if not images_dir.exists():\n",
    "        return False\n",
    "    pngs = list(images_dir.glob(\"*.png\"))\n",
    "    instr_ok = (ep_dir / \"instruction.txt\").exists()\n",
    "    return instr_ok and len(pngs) >= 9\n",
    "\n",
    "# ==== 统计已完成的样本数量（只计算真正完整的）====\n",
    "completed_ids = []\n",
    "for d in sorted(output_dir.iterdir()):\n",
    "    if d.is_dir() and ID_RE.match(d.name) and is_episode_complete(d):\n",
    "        completed_ids.append(int(d.name[-5:]))\n",
    "\n",
    "resume_from = len(completed_ids)  # 已完整完成的 episode 数量\n",
    "print(f\"[INFO] 已完成 {resume_from} 个 episode，将从第 {resume_from+1} 个继续。\")\n",
    "\n",
    "# ==== 计算本次要处理的目标数量 ====\n",
    "if MAX_SAMPLES is None:\n",
    "    to_take = None\n",
    "else:\n",
    "    # 如果之前已经达到/超过 MAX_SAMPLES，就不再处理\n",
    "    remaining = max(0, MAX_SAMPLES - resume_from)\n",
    "    if remaining == 0:\n",
    "        print(\"[INFO] 已达到 MAX_SAMPLES，无需继续。\")\n",
    "        raise SystemExit\n",
    "    to_take = remaining\n",
    "\n",
    "# ==== 基于 skip() 进行续跑 ====\n",
    "ds_resumed = ds.skip(resume_from)\n",
    "if to_take is not None:\n",
    "    ds_resumed = ds_resumed.take(to_take)\n",
    "\n",
    "pbar = tqdm(enumerate(ds_resumed, start=resume_from + 1),\n",
    "            total=to_take, desc=\"Extracting 9 frames (linspace)\")\n",
    "\n",
    "for sample_idx, example in pbar:\n",
    "    steps = list(example[\"steps\"].as_numpy_iterator())\n",
    "    num_steps = len(steps)\n",
    "\n",
    "    ep_dir = output_dir / f\"id{sample_idx:05d}\"\n",
    "    images_dir = ep_dir / \"images\"\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 若该 episode 已完整，直接跳过（防止重复写）\n",
    "    if is_episode_complete(ep_dir):\n",
    "        pbar.set_postfix_str(\"skip (already complete)\")\n",
    "        continue\n",
    "\n",
    "    # === 1. 提取第一步语言指令 ===\n",
    "    lang = steps[0][\"observation\"][\"natural_language_instruction\"].decode(\"utf-8\")\n",
    "\n",
    "    # === 2. 计算9个等间隔索引（包含首帧与末帧） ===\n",
    "    if num_steps <= 9:\n",
    "        frame_indices = np.arange(num_steps)\n",
    "    else:\n",
    "        # 用 round 再转 int，分布更均匀；去重以防 round 碰撞\n",
    "        cand = np.round(np.linspace(0, num_steps - 1, num=9)).astype(int)\n",
    "        frame_indices = np.unique(cand)\n",
    "\n",
    "    # === 3. 保存这些帧 ===\n",
    "    for step_idx in frame_indices:\n",
    "        img = steps[step_idx][\"observa\" \\\n",
    "        \"\" \\\n",
    "        \"\" \\\n",
    "        \"\" \\\n",
    "        \"tion\"][\"image\"]\n",
    "        img_pil = Image.fromarray(img)\n",
    "        img_name = f\"step{step_idx:03d}.png\"\n",
    "        img_pil.save(images_dir / img_name)\n",
    "\n",
    "    # === 4. 保存语言文件 ===\n",
    "    with open(ep_dir / \"instruction.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(lang.strip())\n",
    "\n",
    "pbar.close()\n",
    "print(f\"\\n✅ 续跑完成：从 id{resume_from+1:05d} 开始处理，共新增 {to_take if to_take is not None else '若干'} 个 episode。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0526033a",
   "metadata": {},
   "source": [
    "## 提取视频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117b6299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ==== 基于 bridge/0.1.0 的视频导出（单相机：observation.image） ====\n",
    "import cv2, json\n",
    "from pathlib import Path\n",
    "\n",
    "# === 可配置项 ===\n",
    "OUTPUT_ROOT = Path(r\"F:\\PangYe\\bridgev2_DATA\\videos_train\")  # 导出根目录\n",
    "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "FPS = 15                  # 采样帧率（不知道真实帧率时填 15/20/30 都可）\n",
    "USE_LOSSLESS = True       # 优先无损（FFV1 -> .mkv）\n",
    "MAX_SAMPLES = 25460       # None 表示不限制\n",
    "SAMPLE_PAD = 5            # id00001 的位宽\n",
    "DS_SPLIT = \"train\"        # 仅用于统计信息显示；ds 已在上文用 train 构造\n",
    "\n",
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def decode_str(x) -> str:\n",
    "    if x is None:\n",
    "        return \"\"\n",
    "    if isinstance(x, bytes):\n",
    "        return x.decode(\"utf-8\", errors=\"ignore\")\n",
    "    return str(x)\n",
    "\n",
    "def _make_writer(out_path: Path, frame_size_hw, fps=FPS, lossless=USE_LOSSLESS):\n",
    "    \"\"\"优先 FFV1（.mkv），失败回退 MJPG（.avi）\"\"\"\n",
    "    H, W = map(int, frame_size_hw)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if lossless:\n",
    "        try:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'FFV1')\n",
    "            vw = cv2.VideoWriter(str(out_path.with_suffix('.mkv')), fourcc, fps, (W, H))\n",
    "            if vw.isOpened():\n",
    "                return vw, '.mkv'\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    vw = cv2.VideoWriter(str(out_path.with_suffix('.avi')), fourcc, fps, (W, H))\n",
    "    if not vw.isOpened():\n",
    "        raise RuntimeError(f\"Cannot open VideoWriter for {out_path}\")\n",
    "    return vw, '.avi'\n",
    "\n",
    "# === JSONL（只要首步指令非空就写一行，并导出对应视频） ===\n",
    "jsonl_path = OUTPUT_ROOT / \"language_instructions.jsonl\"\n",
    "jsonl_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "jsonl_f = open(jsonl_path, \"a\", encoding=\"utf-8\")\n",
    "\n",
    "total_examples = info.splits[DS_SPLIT].num_examples or None\n",
    "\n",
    "seen_samples = 0       # 遍历过的样本计数（用于生成连续 sample_id）\n",
    "wrote_videos = 0       # 实际写出视频的样本计数\n",
    "\n",
    "pbar = tqdm(total=(MAX_SAMPLES if MAX_SAMPLES is not None else total_examples),\n",
    "            desc=\"Bridge videos (only if instruction present)\", unit=\"ep\")\n",
    "\n",
    "for sample_index, example in enumerate(ds, start=1):\n",
    "    seen_samples += 1\n",
    "    sample_id = f\"id{seen_samples:0{SAMPLE_PAD}d}\"\n",
    "\n",
    "    if MAX_SAMPLES is not None and seen_samples > MAX_SAMPLES:\n",
    "        pbar.write(f\"[INFO] Reached MAX_SAMPLES={MAX_SAMPLES}; stopping.\")\n",
    "        break\n",
    "\n",
    "    # 没有 steps 的异常样本：跳过（ID 仍占用以保证连续）\n",
    "    if \"steps\" not in example:\n",
    "        pbar.write(f\"[WARN] {sample_id}: no 'steps'; skipped.\")\n",
    "        pbar.update(1)\n",
    "        continue\n",
    "\n",
    "    steps_ds = example[\"steps\"]\n",
    "    if not isinstance(steps_ds, tf.data.Dataset):\n",
    "        pbar.write(f\"[WARN] {sample_id}: 'steps' not tf.data.Dataset; skipped.\")\n",
    "        pbar.update(1)\n",
    "        continue\n",
    "\n",
    "    # 窥视第一步，读取首步自然语言指令（bridge: observation.natural_language_instruction）\n",
    "    first_step_np = None\n",
    "    for _first in steps_ds.take(1):\n",
    "        first_step_np = tf.nest.map_structure(lambda x: x.numpy(), _first)\n",
    "    if first_step_np is None:\n",
    "        pbar.write(f\"[WARN] {sample_id}: 0 steps; skipped.\")\n",
    "        pbar.update(1)\n",
    "        continue\n",
    "\n",
    "    obs0 = first_step_np.get(\"observation\", {})\n",
    "    instr = decode_str(obs0.get(\"natural_language_instruction\", b\"\")).strip()\n",
    "    has_text = bool(instr)\n",
    "\n",
    "    if not has_text:\n",
    "        # 首步文本为空：完全跳过（与“提取视频的方法”一致：只对有文本的样本建视频/写JSONL）\n",
    "        pbar.set_postfix_str(\"skip (empty instruction)\")\n",
    "        pbar.update(1)\n",
    "        continue\n",
    "\n",
    "    # 写 JSONL（仅一条指令）\n",
    "    rec = {\"sample_id\": sample_id, \"instruction\": instr}\n",
    "    jsonl_f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "    jsonl_f.flush()\n",
    "\n",
    "    # 准备输出目录与 writer（单相机：observation.image）\n",
    "    sample_dir = ensure_dir(OUTPUT_ROOT / sample_id)\n",
    "    out_base = sample_dir / \"image\"   # 不带扩展名；根据编码自动加 .mkv / .avi\n",
    "\n",
    "    writer = None\n",
    "    suffix = None\n",
    "    frame_size = None\n",
    "    frames_written = 0\n",
    "\n",
    "    # 逐步写帧\n",
    "    for t, step in enumerate(steps_ds):\n",
    "        step_np = tf.nest.map_structure(lambda x: x.numpy(), step)\n",
    "        obs = step_np.get(\"observation\", {})\n",
    "        if \"image\" not in obs:\n",
    "            pbar.write(f\"[WARN] {sample_id} step {t}: missing observation.image; frame skipped.\")\n",
    "            continue\n",
    "\n",
    "        rgb = obs[\"image\"]  # (H, W, 3) uint8\n",
    "        if frame_size is None:\n",
    "            H, W = int(rgb.shape[0]), int(rgb.shape[1])\n",
    "            frame_size = (H, W)\n",
    "            writer, suffix = _make_writer(out_base, frame_size, fps=FPS, lossless=USE_LOSSLESS)\n",
    "\n",
    "        bgr = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "        writer.write(bgr)\n",
    "        frames_written += 1\n",
    "\n",
    "    # 关闭 writer\n",
    "    if writer is not None:\n",
    "        writer.release()\n",
    "\n",
    "    if frames_written == 0:\n",
    "        pbar.write(f\"[WARN] {sample_id}: no valid frames written; video likely empty.\")\n",
    "    else:\n",
    "        wrote_videos += 1\n",
    "\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "jsonl_f.close()\n",
    "\n",
    "print(f\"Language JSONL saved to: {jsonl_path}\")\n",
    "print(f\"Seen samples (IDs assigned): {seen_samples}\")\n",
    "print(f\"Episodes with videos written: {wrote_videos}\")\n",
    "print(f\"Output root: {OUTPUT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ec97f7",
   "metadata": {},
   "source": [
    "## 第一帧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6d63342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting first frame only: 100%|██████████| 1000/1000 [01:06<00:00, 14.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 提取完成（每个 episode 仅保存第一帧），共保存 1000 个 episode。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==== 迭代样本（仅提取第一帧） ====\n",
    "output_path  = r\"E:\\bridgev2_DATA\\extracted_first_train\" # 输出目录\n",
    "output_dir = Path(output_path)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "max_samples = 1000                    # None 表示全部样本；设为整数表示只处理这么多\n",
    "\n",
    "\n",
    "pbar = tqdm(enumerate(ds.take(max_samples), start=1), total=max_samples, desc=\"Extracting first frame only\")\n",
    "\n",
    "for sample_idx, example in pbar:\n",
    "    steps = list(example[\"steps\"].as_numpy_iterator())\n",
    "\n",
    "    # ep_dir = output_dir / f\"id{sample_idx:05d}\"\n",
    "    # images_dir = ep_dir / \"images\"\n",
    "    # images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # === 1. 第一步的 step ===\n",
    "    first_step = steps[0]\n",
    "    img = first_step[\"observation\"][\"image\"]\n",
    "    lang = first_step[\"observation\"][\"natural_language_instruction\"].decode(\"utf-8\")\n",
    "\n",
    "    # === 2. 保存图像 ===\n",
    "    img_pil = Image.fromarray(img)\n",
    "    img_pil.save(output_dir / f\"id{sample_idx:05d}_step001.png\")\n",
    "\n",
    "    # # === 3. 保存语言文件 ===\n",
    "    # with open(ep_dir / \"instruction.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    #     f.write(lang.strip())\n",
    "\n",
    "pbar.close()\n",
    "print(f\"\\n✅ 提取完成（每个 episode 仅保存第一帧），共保存 {min(max_samples, builder.info.splits[split].num_examples)} 个 episode。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f7888d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting first frame only: 100%|██████████| 550/550 [00:41<00:00, 13.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 提取完成（每个 episode 仅保存第一帧），共保存 550 个 episode。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_path = r\"E:\\bridgev2_DATA\\extracted_first_test_2\"  # 输出根目录\n",
    "output_dir = Path(output_path)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "max_samples = 550  # None 表示全部样本；设为整数表示只处理这么多\n",
    "batch_size  = 1000  # 每1000个样本一个子文件夹\n",
    "\n",
    "pbar = tqdm(enumerate(ds.take(max_samples), start=1), total=max_samples, desc=\"Extracting first frame only\")\n",
    "\n",
    "for sample_idx, example in pbar:\n",
    "    steps = list(example[\"steps\"].as_numpy_iterator())\n",
    "    first_step = steps[0]\n",
    "    img = first_step[\"observation\"][\"image\"]\n",
    "    lang = first_step[\"observation\"][\"natural_language_instruction\"].decode(\"utf-8\")\n",
    "\n",
    "    # === 计算当前 batch 号（从1开始） ===\n",
    "    batch_id = (sample_idx - 1) // batch_size + 1\n",
    "    batch_dir = output_dir / f\"batch_{batch_id:05d}\"\n",
    "    batch_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # === 保存图像 ===\n",
    "    img_pil = Image.fromarray(img)\n",
    "    img_pil.save(batch_dir / f\"id{sample_idx:05d}_step001.png\")\n",
    "\n",
    "    # === 保存语言文件 ===\n",
    "    # with open(batch_dir / f\"id{sample_idx:05d}_instruction.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    #     f.write(lang.strip())\n",
    "\n",
    "pbar.close()\n",
    "print(f\"\\n✅ 提取完成（每个 episode 仅保存第一帧），共保存 {min(max_samples, builder.info.splits[split].num_examples)} 个 episode。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfds2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
