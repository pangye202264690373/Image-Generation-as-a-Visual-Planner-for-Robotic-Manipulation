{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4cfe917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ==== 参数设置 ====\n",
    "builder_dir = r\"F:\\PangYe\\bridgev2\\0.1.0\"      # TFDS 数据目录（含 dataset_info.json / features.json / tfrecord-*）\n",
    "split       = \"train\"\n",
    "# frame_indices = [0]                 # [0]=第一帧；[-1]=最后一帧；[0, -1]=第一+最后；None=全部帧\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "176a9b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name: bridge\n",
      "Dataset Version: 0.1.0\n",
      "Dataset Homepage: https://rail-berkeley.github.io/bridgedata/\n",
      "Dataset Description: WidowX interacting with toy kitchens\n",
      "\n",
      "Splits Information:\n",
      "train: 25460 examples, 365,981,955,835 bytes\n",
      "test: 3475 examples, 50,084,717,377 bytes\n",
      "\n",
      "Features:\n",
      "FeaturesDict({\n",
      "    'steps': Dataset({\n",
      "        'action': FeaturesDict({\n",
      "            'open_gripper': bool,\n",
      "            'rotation_delta': Tensor(shape=(3,), dtype=float32),\n",
      "            'terminate_episode': float32,\n",
      "            'world_vector': Tensor(shape=(3,), dtype=float32),\n",
      "        }),\n",
      "        'is_first': bool,\n",
      "        'is_last': bool,\n",
      "        'is_terminal': bool,\n",
      "        'observation': FeaturesDict({\n",
      "            'image': Image(shape=(480, 640, 3), dtype=uint8),\n",
      "            'natural_language_embedding': Tensor(shape=(512,), dtype=float32),\n",
      "            'natural_language_instruction': string,\n",
      "            'state': Tensor(shape=(7,), dtype=float32),\n",
      "        }),\n",
      "        'reward': Scalar(shape=(), dtype=float32),\n",
      "    }),\n",
      "})\n",
      "\n",
      "Supervised Keys:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 使用 builder_from_directory 加载数据集\n",
    "builder = tfds.builder_from_directory(builder_dir)\n",
    "\n",
    "# 获取数据集的 info 信息\n",
    "info = builder.info\n",
    "\n",
    "# 打印数据集的基本信息\n",
    "print(\"Dataset Name:\", builder.name)\n",
    "print(\"Dataset Version:\", info.version)\n",
    "print(\"Dataset Homepage:\", info.homepage)\n",
    "print(\"Dataset Description:\", info.description)\n",
    "\n",
    "# 打印 splits 信息\n",
    "print(\"\\nSplits Information:\")\n",
    "for split, split_info in info.splits.items():\n",
    "    print(f\"{split}: {split_info.num_examples} examples, {split_info.num_bytes:,} bytes\")\n",
    "\n",
    "# 打印 features 信息\n",
    "print(\"\\nFeatures:\")\n",
    "print(info.features)\n",
    "\n",
    "# 打印监督的键\n",
    "print(\"\\nSupervised Keys:\")\n",
    "print(info.supervised_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c470e562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='bridge',\n",
      "    full_name='bridge/0.1.0',\n",
      "    description=\"\"\"\n",
      "    WidowX interacting with toy kitchens\n",
      "    \"\"\",\n",
      "    homepage='https://rail-berkeley.github.io/bridgedata/',\n",
      "    data_dir='F:\\\\PangYe\\\\bridgev2\\\\0.1.0',\n",
      "    file_format=tfrecord,\n",
      "    download_size=Unknown size,\n",
      "    dataset_size=387.49 GiB,\n",
      "    features=FeaturesDict({\n",
      "        'steps': Dataset({\n",
      "            'action': FeaturesDict({\n",
      "                'open_gripper': bool,\n",
      "                'rotation_delta': Tensor(shape=(3,), dtype=float32),\n",
      "                'terminate_episode': float32,\n",
      "                'world_vector': Tensor(shape=(3,), dtype=float32),\n",
      "            }),\n",
      "            'is_first': bool,\n",
      "            'is_last': bool,\n",
      "            'is_terminal': bool,\n",
      "            'observation': FeaturesDict({\n",
      "                'image': Image(shape=(480, 640, 3), dtype=uint8),\n",
      "                'natural_language_embedding': Tensor(shape=(512,), dtype=float32),\n",
      "                'natural_language_instruction': string,\n",
      "                'state': Tensor(shape=(7,), dtype=float32),\n",
      "            }),\n",
      "            'reward': Scalar(shape=(), dtype=float32),\n",
      "        }),\n",
      "    }),\n",
      "    supervised_keys=None,\n",
      "    disable_shuffling=False,\n",
      "    nondeterministic_order=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=3475, num_shards=512>,\n",
      "        'train': <SplitInfo num_examples=25460, num_shards=1024>,\n",
      "    },\n",
      "    citation=\"\"\"@inproceedings{walke2023bridgedata,\n",
      "        title={BridgeData V2: A Dataset for Robot Learning at Scale},\n",
      "        author={Walke, Homer and Black, Kevin and Lee, Abraham and Kim, Moo Jin and Du, Max and Zheng, Chongyi and Zhao, Tony and Hansen-Estruch, Philippe and Vuong, Quan and He, Andre and Myers, Vivek and Fang, Kuan and Finn, Chelsea and Levine, Sergey},\n",
      "        booktitle={Conference on Robot Learning (CoRL)},\n",
      "        year={2023}\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ebd9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = builder.as_dataset(split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4509e587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting samples:  24%|██▎       | 6033/25460 [01:33<05:01, 64.53it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m count = \u001b[32m0\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 这里不再使用 ds[split]，因为 ds 已经是一个 Dataset 了\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_to_check\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCounting samples\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ROG_STRIX\\.conda\\envs\\tfds2\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ROG_STRIX\\.conda\\envs\\tfds2\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:826\u001b[39m, in \u001b[36mOwnedIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    825\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m826\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    827\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m errors.OutOfRangeError:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ROG_STRIX\\.conda\\envs\\tfds2\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:776\u001b[39m, in \u001b[36mOwnedIterator._next_internal\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[32m    774\u001b[39m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context.execution_mode(context.SYNC):\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m   ret = \u001b[43mgen_dataset_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    781\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    782\u001b[39m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[32m    783\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._element_spec._from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ROG_STRIX\\.conda\\envs\\tfds2\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3081\u001b[39m, in \u001b[36miterator_get_next\u001b[39m\u001b[34m(iterator, output_types, output_shapes, name)\u001b[39m\n\u001b[32m   3079\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m   3080\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3081\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mIteratorGetNext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_types\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m      \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_shapes\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3084\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   3085\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "max_to_check = 100000  # 防止太慢，可设大一点\n",
    "count = 0\n",
    "\n",
    "# 这里不再使用 ds[split]，因为 ds 已经是一个 Dataset 了\n",
    "for _ in tqdm(ds.take(max_to_check), desc=\"Counting samples\"):\n",
    "    count += 1\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f718cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = builder.as_dataset(split=\"test\")\n",
    "max_to_check = 100000  # 防止太慢，可设大一点\n",
    "count = 0\n",
    "\n",
    "# 这里不再使用 ds[split]，因为 ds 已经是一个 Dataset 了\n",
    "for _ in tqdm(ds2.take(max_to_check), desc=\"Counting samples\"):\n",
    "    count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfds2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
