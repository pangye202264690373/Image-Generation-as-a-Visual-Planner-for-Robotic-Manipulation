{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4cfe917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ==== 参数设置 ====\n",
    "builder_dir = r\"F:\\PangYe\\bridgev2\\0.1.0\"      # TFDS 数据目录（含 dataset_info.json / features.json / tfrecord-*）\n",
    "# split       = \"train\"\n",
    "# frame_indices = [0]                 # [0]=第一帧；[-1]=最后一帧；[0, -1]=第一+最后；None=全部帧\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "176a9b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name: bridge\n",
      "Dataset Version: 0.1.0\n",
      "Dataset Homepage: https://rail-berkeley.github.io/bridgedata/\n",
      "Dataset Description: WidowX interacting with toy kitchens\n",
      "\n",
      "Splits Information:\n",
      "train: 25460 examples, 365,981,955,835 bytes\n",
      "test: 3475 examples, 50,084,717,377 bytes\n",
      "\n",
      "Info:\n",
      "tfds.core.DatasetInfo(\n",
      "    name='bridge',\n",
      "    full_name='bridge/0.1.0',\n",
      "    description=\"\"\"\n",
      "    WidowX interacting with toy kitchens\n",
      "    \"\"\",\n",
      "    homepage='https://rail-berkeley.github.io/bridgedata/',\n",
      "    data_dir='F:\\\\PangYe\\\\bridgev2\\\\0.1.0',\n",
      "    file_format=tfrecord,\n",
      "    download_size=Unknown size,\n",
      "    dataset_size=387.49 GiB,\n",
      "    features=FeaturesDict({\n",
      "        'steps': Dataset({\n",
      "            'action': FeaturesDict({\n",
      "                'open_gripper': bool,\n",
      "                'rotation_delta': Tensor(shape=(3,), dtype=float32),\n",
      "                'terminate_episode': float32,\n",
      "                'world_vector': Tensor(shape=(3,), dtype=float32),\n",
      "            }),\n",
      "            'is_first': bool,\n",
      "            'is_last': bool,\n",
      "            'is_terminal': bool,\n",
      "            'observation': FeaturesDict({\n",
      "                'image': Image(shape=(480, 640, 3), dtype=uint8),\n",
      "                'natural_language_embedding': Tensor(shape=(512,), dtype=float32),\n",
      "                'natural_language_instruction': string,\n",
      "                'state': Tensor(shape=(7,), dtype=float32),\n",
      "            }),\n",
      "            'reward': Scalar(shape=(), dtype=float32),\n",
      "        }),\n",
      "    }),\n",
      "    supervised_keys=None,\n",
      "    disable_shuffling=False,\n",
      "    nondeterministic_order=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=3475, num_shards=512>,\n",
      "        'train': <SplitInfo num_examples=25460, num_shards=1024>,\n",
      "    },\n",
      "    citation=\"\"\"@inproceedings{walke2023bridgedata,\n",
      "        title={BridgeData V2: A Dataset for Robot Learning at Scale},\n",
      "        author={Walke, Homer and Black, Kevin and Lee, Abraham and Kim, Moo Jin and Du, Max and Zheng, Chongyi and Zhao, Tony and Hansen-Estruch, Philippe and Vuong, Quan and He, Andre and Myers, Vivek and Fang, Kuan and Finn, Chelsea and Levine, Sergey},\n",
      "        booktitle={Conference on Robot Learning (CoRL)},\n",
      "        year={2023}\n",
      "    }\"\"\",\n",
      ")\n",
      "\n",
      "Supervised Keys:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 使用 builder_from_directory 加载数据集\n",
    "builder = tfds.builder_from_directory(builder_dir)\n",
    "\n",
    "# 获取数据集的 info 信息\n",
    "info = builder.info\n",
    "\n",
    "# 打印数据集的基本信息\n",
    "print(\"Dataset Name:\", builder.name)\n",
    "print(\"Dataset Version:\", info.version)\n",
    "print(\"Dataset Homepage:\", info.homepage)\n",
    "print(\"Dataset Description:\", info.description)\n",
    "\n",
    "# 打印 splits 信息\n",
    "print(\"\\nSplits Information:\")\n",
    "for split, split_info in info.splits.items():\n",
    "    print(f\"{split}: {split_info.num_examples} examples, {split_info.num_bytes:,} bytes\")\n",
    "\n",
    "# 打印 features 信息\n",
    "print(\"\\nInfo:\")\n",
    "print(info)\n",
    "\n",
    "# 打印监督的键\n",
    "print(\"\\nSupervised Keys:\")\n",
    "print(info.supervised_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ebd9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = builder.as_dataset(split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e12fdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting samples:   0%|          | 0/3475 [00:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "max_to_check = 100000  # 防止太慢，可设大一点\n",
    "count = 0\n",
    "\n",
    "# 这里不再使用 ds[split]，因为 ds 已经是一个 Dataset 了\n",
    "for _ in tqdm(ds.take(max_to_check), desc=\"Counting samples\"):\n",
    "    count += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629213f5",
   "metadata": {},
   "source": [
    "## 分别提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712e8803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting samples: 100%|██████████| 10/10 [00:10<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 提取完成，共保存 10 个 episode。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==== 输出准备 ====\n",
    "output_path  = r\"F:\\PangYe\\bridgev2_DATA\\extracted\" # 输出目录\n",
    "output_dir = Path(output_path)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "max_samples = 10                     # None 表示全部样本；设为整数表示只处理这么多\n",
    "\n",
    "# ==== 迭代样本 ====\n",
    "pbar = tqdm(enumerate(ds.take(max_samples), start=1), total=max_samples, desc=\"Extracting samples\")\n",
    "\n",
    "for sample_idx, example in pbar:\n",
    "    steps = example[\"steps\"]\n",
    "\n",
    "    # 创建当前 episode 文件夹：id00001, id00002, ...\n",
    "    ep_dir = output_dir / f\"id{sample_idx:05d}\"\n",
    "    images_dir = ep_dir / \"images\"\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    lang = None\n",
    "\n",
    "    # 遍历 step 并保存图片\n",
    "    for step_idx, step in enumerate(steps.as_numpy_iterator(), start=1):\n",
    "        img = step[\"observation\"][\"image\"]\n",
    "        lang_text = step[\"observation\"][\"natural_language_instruction\"].decode(\"utf-8\")\n",
    "\n",
    "        # 记录第一步的自然语言指令\n",
    "        if step_idx == 1:\n",
    "            lang = lang_text\n",
    "\n",
    "        # 保存图像到 images/ 目录\n",
    "        img_pil = Image.fromarray(img)\n",
    "        img_name = f\"step{step_idx:03d}.png\"\n",
    "        img_pil.save(images_dir / img_name)\n",
    "\n",
    "    # 保存语言到 instruction.txt（与 images 平级）\n",
    "    if lang is not None:\n",
    "        with open(ep_dir / \"instruction.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(lang.strip())\n",
    "\n",
    "pbar.close()\n",
    "print(f\"\\n✅ 提取完成，共保存 {min(max_samples, builder.info.splits[split].num_examples)} 个 episode。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79ff27e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting samples: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 提取完成，共保存 10 个 episode。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==== 输出准备 ====\n",
    "output_path  = r\"F:\\PangYe\\bridgev2_DATA\\extracted_1\" # 输出目录\n",
    "output_dir = Path(output_path)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "max_samples = 10                     # None 表示全部样本；设为整数表示只处理这么多\n",
    "\n",
    "# ==== 迭代样本 ====\n",
    "pbar = tqdm(enumerate(ds.take(max_samples), start=1), total=max_samples, desc=\"Extracting samples\")\n",
    "\n",
    "for sample_idx, example in pbar:\n",
    "    steps = example[\"steps\"]\n",
    "\n",
    "    # 创建当前 episode 文件夹：id00001, id00002, ...\n",
    "    ep_dir = output_dir / f\"id{sample_idx:05d}\"\n",
    "    ep_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # === 1. 记录首步语言指令 ===\n",
    "    lang = None\n",
    "\n",
    "    # === 2. 遍历 step 并保存图片 ===\n",
    "    for step_idx, step in enumerate(steps.as_numpy_iterator(), start=1):\n",
    "        img = step[\"observation\"][\"image\"]\n",
    "        lang_text = step[\"observation\"][\"natural_language_instruction\"].decode(\"utf-8\")\n",
    "\n",
    "        # 保存第一个 step 的语言\n",
    "        if step_idx == 1:\n",
    "            lang = lang_text\n",
    "\n",
    "        # 保存图像\n",
    "        img_pil = Image.fromarray(img)\n",
    "        img_name = f\"step{step_idx:03d}.png\"\n",
    "        img_pil.save(ep_dir / img_name)\n",
    "\n",
    "    # === 3. 保存语言到 txt 文件 ===\n",
    "    if lang is not None:\n",
    "        with open(ep_dir / \"instruction.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(lang.strip())\n",
    "\n",
    "pbar.close()\n",
    "print(f\"\\n✅ 提取完成，共保存 {min(max_samples, builder.info.splits[split].num_examples)} 个 episode。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01904eb",
   "metadata": {},
   "source": [
    "## 取九"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd67b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting 9 frames (linspace):  10%|█         | 2593/25460 [15:59<2:21:00,  2.70it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'F:\\\\PangYe\\\\bridgev2_DATA\\\\extracted_nine_train\\\\id02594\\\\images\\\\step028.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m     img_pil = Image.fromarray(img)\n\u001b[32m     31\u001b[39m     img_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstep\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep_idx\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.png\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[43mimg_pil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# === 4. 保存语言文件 ===\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(ep_dir / \u001b[33m\"\u001b[39m\u001b[33minstruction.txt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ROG_STRIX\\.conda\\envs\\tfds2\\Lib\\site-packages\\PIL\\Image.py:2566\u001b[39m, in \u001b[36mImage.save\u001b[39m\u001b[34m(self, fp, format, **params)\u001b[39m\n\u001b[32m   2564\u001b[39m         fp = builtins.open(filename, \u001b[33m\"\u001b[39m\u001b[33mr+b\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2565\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2566\u001b[39m         fp = builtins.open(filename, \u001b[33m\"\u001b[39m\u001b[33mw+b\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2567\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2568\u001b[39m     fp = cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n",
      "\u001b[31mOSError\u001b[39m: [Errno 22] Invalid argument: 'F:\\\\PangYe\\\\bridgev2_DATA\\\\extracted_nine_train\\\\id02594\\\\images\\\\step028.png'"
     ]
    }
   ],
   "source": [
    "# ==== 迭代样本（使用 np.linspace 采样9帧，含首尾） ====\n",
    "output_path  = r\"F:\\PangYe\\bridgev2_DATA\\extracted_nine_test\" # 输出目录\n",
    "output_dir = Path(output_path)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "max_samples = 3475                     # None 表示全部样本；设为整数表示只处理这么多\n",
    "\n",
    "pbar = tqdm(enumerate(ds.take(max_samples), start=1), total=max_samples, desc=\"Extracting 9 frames (linspace)\")\n",
    "\n",
    "\n",
    "for sample_idx, example in pbar:\n",
    "    steps = list(example[\"steps\"].as_numpy_iterator())\n",
    "    num_steps = len(steps)\n",
    "\n",
    "    ep_dir = output_dir / f\"id{sample_idx:05d}\"\n",
    "    images_dir = ep_dir / \"images\"\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # === 1. 提取第一步语言指令 ===\n",
    "    lang = steps[0][\"observation\"][\"natural_language_instruction\"].decode(\"utf-8\")\n",
    "\n",
    "    # === 2. 计算9个等间隔索引（包含首帧与末帧） ===\n",
    "    if num_steps <= 9:\n",
    "        frame_indices = np.arange(num_steps)\n",
    "    else:\n",
    "        frame_indices = np.linspace(0, num_steps - 1, num=9, dtype=int)\n",
    "\n",
    "    # === 3. 保存这些帧 ===\n",
    "    for local_idx, step_idx in enumerate(frame_indices, start=1):\n",
    "        img = steps[step_idx][\"observation\"][\"image\"]\n",
    "        img_pil = Image.fromarray(img)\n",
    "        img_name = f\"step{step_idx:03d}.png\"\n",
    "        img_pil.save(images_dir / img_name)\n",
    "\n",
    "    # === 4. 保存语言文件 ===\n",
    "    with open(ep_dir / \"instruction.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(lang.strip())\n",
    "\n",
    "pbar.close()\n",
    "print(f\"\\n✅ 提取完成（每个 episode 使用 np.linspace 等间隔选取 9 帧，含首尾），共保存 {min(max_samples, builder.info.splits[split].num_examples)} 个 episode。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0700e4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 已完成 0 个 episode，将从第 1 个继续。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting 9 frames (linspace): 100%|██████████| 3475/3475 [25:47<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 续跑完成：从 id00001 开始处理，共新增 3475 个 episode。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==== 配置 ====\n",
    "output_path  = r\"F:\\PangYe\\bridgev2_DATA\\extracted_nine_test\"\n",
    "output_dir = Path(output_path)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "MAX_SAMPLES = 3475   # None 表示不限制\n",
    "\n",
    "ID_RE = re.compile(r\"^id(\\d{5})$\")\n",
    "\n",
    "def is_episode_complete(ep_dir: Path) -> bool:\n",
    "    \"\"\"判断该 episode 是否完整（有 instruction.txt 且 images 里 >=9 张）\"\"\"\n",
    "    images_dir = ep_dir / \"images\"\n",
    "    if not images_dir.exists():\n",
    "        return False\n",
    "    pngs = list(images_dir.glob(\"*.png\"))\n",
    "    instr_ok = (ep_dir / \"instruction.txt\").exists()\n",
    "    return instr_ok and len(pngs) >= 9\n",
    "\n",
    "# ==== 统计已完成的样本数量（只计算真正完整的）====\n",
    "completed_ids = []\n",
    "for d in sorted(output_dir.iterdir()):\n",
    "    if d.is_dir() and ID_RE.match(d.name) and is_episode_complete(d):\n",
    "        completed_ids.append(int(d.name[-5:]))\n",
    "\n",
    "resume_from = len(completed_ids)  # 已完整完成的 episode 数量\n",
    "print(f\"[INFO] 已完成 {resume_from} 个 episode，将从第 {resume_from+1} 个继续。\")\n",
    "\n",
    "# ==== 计算本次要处理的目标数量 ====\n",
    "if MAX_SAMPLES is None:\n",
    "    to_take = None\n",
    "else:\n",
    "    # 如果之前已经达到/超过 MAX_SAMPLES，就不再处理\n",
    "    remaining = max(0, MAX_SAMPLES - resume_from)\n",
    "    if remaining == 0:\n",
    "        print(\"[INFO] 已达到 MAX_SAMPLES，无需继续。\")\n",
    "        raise SystemExit\n",
    "    to_take = remaining\n",
    "\n",
    "# ==== 基于 skip() 进行续跑 ====\n",
    "ds_resumed = ds.skip(resume_from)\n",
    "if to_take is not None:\n",
    "    ds_resumed = ds_resumed.take(to_take)\n",
    "\n",
    "pbar = tqdm(enumerate(ds_resumed, start=resume_from + 1),\n",
    "            total=to_take, desc=\"Extracting 9 frames (linspace)\")\n",
    "\n",
    "for sample_idx, example in pbar:\n",
    "    steps = list(example[\"steps\"].as_numpy_iterator())\n",
    "    num_steps = len(steps)\n",
    "\n",
    "    ep_dir = output_dir / f\"id{sample_idx:05d}\"\n",
    "    images_dir = ep_dir / \"images\"\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 若该 episode 已完整，直接跳过（防止重复写）\n",
    "    if is_episode_complete(ep_dir):\n",
    "        pbar.set_postfix_str(\"skip (already complete)\")\n",
    "        continue\n",
    "\n",
    "    # === 1. 提取第一步语言指令 ===\n",
    "    lang = steps[0][\"observation\"][\"natural_language_instruction\"].decode(\"utf-8\")\n",
    "\n",
    "    # === 2. 计算9个等间隔索引（包含首帧与末帧） ===\n",
    "    if num_steps <= 9:\n",
    "        frame_indices = np.arange(num_steps)\n",
    "    else:\n",
    "        # 用 round 再转 int，分布更均匀；去重以防 round 碰撞\n",
    "        cand = np.round(np.linspace(0, num_steps - 1, num=9)).astype(int)\n",
    "        frame_indices = np.unique(cand)\n",
    "\n",
    "    # === 3. 保存这些帧 ===\n",
    "    for step_idx in frame_indices:\n",
    "        img = steps[step_idx][\"observation\"][\"image\"]\n",
    "        img_pil = Image.fromarray(img)\n",
    "        img_name = f\"step{step_idx:03d}.png\"\n",
    "        img_pil.save(images_dir / img_name)\n",
    "\n",
    "    # === 4. 保存语言文件 ===\n",
    "    with open(ep_dir / \"instruction.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(lang.strip())\n",
    "\n",
    "pbar.close()\n",
    "print(f\"\\n✅ 续跑完成：从 id{resume_from+1:05d} 开始处理，共新增 {to_take if to_take is not None else '若干'} 个 episode。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6d63342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting first frame only: 100%|██████████| 100/100 [00:13<00:00,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 提取完成（每个 episode 仅保存第一帧），共保存 100 个 episode。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==== 迭代样本（仅提取第一帧） ====\n",
    "output_path  = r\"F:\\PangYe\\bridgev2_DATA\\extracted_first_100\" # 输出目录\n",
    "output_dir = Path(output_path)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "max_samples = 100                     # None 表示全部样本；设为整数表示只处理这么多\n",
    "\n",
    "\n",
    "pbar = tqdm(enumerate(ds.take(max_samples), start=1), total=max_samples, desc=\"Extracting first frame only\")\n",
    "\n",
    "for sample_idx, example in pbar:\n",
    "    steps = list(example[\"steps\"].as_numpy_iterator())\n",
    "\n",
    "    ep_dir = output_dir / f\"id{sample_idx:05d}\"\n",
    "    images_dir = ep_dir / \"images\"\n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # === 1. 第一步的 step ===\n",
    "    first_step = steps[0]\n",
    "    img = first_step[\"observation\"][\"image\"]\n",
    "    lang = first_step[\"observation\"][\"natural_language_instruction\"].decode(\"utf-8\")\n",
    "\n",
    "    # === 2. 保存图像 ===\n",
    "    img_pil = Image.fromarray(img)\n",
    "    img_pil.save(images_dir / \"step001.png\")\n",
    "\n",
    "    # === 3. 保存语言文件 ===\n",
    "    with open(ep_dir / \"instruction.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(lang.strip())\n",
    "\n",
    "pbar.close()\n",
    "print(f\"\\n✅ 提取完成（每个 episode 仅保存第一帧），共保存 {min(max_samples, builder.info.splits[split].num_examples)} 个 episode。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfds2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
