{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e641c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [on]\n",
      "Loading model from: /root/PhotoDoodle/lpips/weights/v0.1/alex.pth\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # 3×3 Grid 合成图 质量评估 Notebook\n",
    "# 使用 tile-wise 适配（避免整图 resize 跨格模糊） + 扁平化指标记录\n",
    "\n",
    "# %%\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "# ==== 配置区 ====\n",
    "CONFIG = {\n",
    "    \"jsonl_path\": \"/root/PhotoDoodle/data/bridge_test/traj_test_index.jsonl\",  # 原始 JSONL 路径\n",
    "    \"output_dir\": \"inference/outputs_bridgeV2_traj_noop\",                            # 生成结果文件夹\n",
    "    \"tile_fit_mode\": \"tile_gt_to_gen\",    # 模式: \"tile_strict\" | \"tile_gen_to_gt\" | \"tile_gt_to_gen\"\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"only_final\": False                    # 是否只比较最后一帧\n",
    "}\n",
    "\n",
    "# 导入指标函数（来自 common_metrics_on_video_quality）\n",
    "from calculate_fvd   import calculate_fvd\n",
    "from calculate_psnr  import calculate_psnr\n",
    "from calculate_ssim  import calculate_ssim\n",
    "from calculate_lpips import calculate_lpips\n",
    "from calculate_mse   import calculate_mse\n",
    "\n",
    "# %%\n",
    "# ==== 工具函数 ====\n",
    "def resolve_path_maybe_relative(p: str, base: Path) -> Path:\n",
    "    pp = Path(p)\n",
    "    return pp if pp.is_absolute() else (base / pp).resolve()\n",
    "\n",
    "def _grid_splits(length: int) -> List[int]:\n",
    "    edges = np.linspace(0, length, 4)\n",
    "    return [int(round(x)) for x in edges]\n",
    "\n",
    "def _cut_3x3_tiles(im: Image.Image) -> List[Image.Image]:\n",
    "    W, H = im.size\n",
    "    xs = _grid_splits(W)\n",
    "    ys = _grid_splits(H)\n",
    "    boxes_linear = [(xs[c], ys[r], xs[c+1], ys[r+1]) for r in range(3) for c in range(3)]\n",
    "    order = [0, 1, 2, 5, 4, 3, 6, 7, 8]\n",
    "    return [im.crop(boxes_linear[idx]) for idx in order]\n",
    "\n",
    "def _tile_sizes(tiles: List[Image.Image]) -> List[Tuple[int,int]]:\n",
    "    return [t.size for t in tiles]\n",
    "\n",
    "def _resize_tiles_to(tiles: List[Image.Image], target_sizes: List[Tuple[int,int]]) -> List[Image.Image]:\n",
    "    out = []\n",
    "    for t, (tw, th) in zip(tiles, target_sizes):\n",
    "        out.append(t if t.size==(tw,th) else t.resize((tw, th), Image.BICUBIC))\n",
    "    return out\n",
    "\n",
    "def _tiles_to_tensor(tiles: List[Image.Image]) -> torch.Tensor:\n",
    "    frames = []\n",
    "    for t in tiles:\n",
    "        arr = np.asarray(t, dtype=np.uint8)\n",
    "        ten = torch.from_numpy(arr).permute(2, 0, 1).float() / 255.0\n",
    "        frames.append(ten)\n",
    "    return torch.stack(frames, dim=0)   # [T=9, C=3, H, W]\n",
    "\n",
    "def cut_grid_as_video_tilefit(gt_path: Path, gen_path: Path, tile_fit_mode: str) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    gt_im  = Image.open(gt_path).convert(\"RGB\")\n",
    "    gen_im = Image.open(gen_path).convert(\"RGB\")\n",
    "\n",
    "    gt_tiles  = _cut_3x3_tiles(gt_im)\n",
    "    gen_tiles = _cut_3x3_tiles(gen_im)\n",
    "\n",
    "    if tile_fit_mode == \"tile_strict\":\n",
    "        if _tile_sizes(gt_tiles) != _tile_sizes(gen_tiles):\n",
    "            gt_im.close(); gen_im.close()\n",
    "            raise AssertionError(f\"[tile_strict] per-tile sizes mismatch: GT={_tile_sizes(gt_tiles)} vs GEN={_tile_sizes(gen_tiles)}\")\n",
    "\n",
    "    elif tile_fit_mode == \"tile_gen_to_gt\":\n",
    "        target_sizes = _tile_sizes(gt_tiles)\n",
    "        gen_tiles = _resize_tiles_to(gen_tiles, target_sizes)\n",
    "\n",
    "    elif tile_fit_mode == \"tile_gt_to_gen\":\n",
    "        target_sizes = _tile_sizes(gen_tiles)\n",
    "        gt_tiles = _resize_tiles_to(gt_tiles, target_sizes)\n",
    "\n",
    "    else:\n",
    "        gt_im.close(); gen_im.close()\n",
    "        raise ValueError(f\"Unknown tile_fit_mode: {tile_fit_mode}\")\n",
    "\n",
    "    v_gt  = _tiles_to_tensor(gt_tiles)\n",
    "    v_gen = _tiles_to_tensor(gen_tiles)\n",
    "\n",
    "    gt_im.close(); gen_im.close()\n",
    "    return v_gt, v_gen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6044cf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PAIRING] total_lines=516, usable_pairs=516, no_target_field=0, missing_files=0\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# ==== 收集配对 ====\n",
    "cfg        = CONFIG\n",
    "JSONL_PATH  = Path(cfg[\"jsonl_path\"]).resolve()\n",
    "JSONL_BASE  = JSONL_PATH.parent\n",
    "OUTPUT_DIR  = Path(cfg[\"output_dir\"]).resolve()\n",
    "RESULTS_PATH= OUTPUT_DIR / \"results.jsonl\"\n",
    "\n",
    "pairs: List[Tuple[Path, Path, dict]] = []\n",
    "n_total = n_usable = n_no_target = n_missing = 0\n",
    "\n",
    "assert RESULTS_PATH.exists(), f\"results.jsonl not found: {RESULTS_PATH}\"\n",
    "with open(RESULTS_PATH, \"r\", encoding=\"utf-8\") as fr:\n",
    "    for line in fr:\n",
    "        n_total += 1\n",
    "        try:\n",
    "            rec = json.loads(line)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if not rec.get(\"ok\", False):\n",
    "            continue\n",
    "        out_rel = rec.get(\"output\")\n",
    "        if not out_rel:\n",
    "            continue\n",
    "        gen_path = (OUTPUT_DIR / out_rel).resolve()\n",
    "\n",
    "        gt_raw = rec.get(\"target\") or rec.get(\"gt\")\n",
    "        if not gt_raw:\n",
    "            n_no_target += 1\n",
    "            continue\n",
    "        gt_path = resolve_path_maybe_relative(gt_raw, JSONL_BASE)\n",
    "\n",
    "        if not (gen_path.exists() and gt_path.exists()):\n",
    "            n_missing += 1\n",
    "            continue\n",
    "\n",
    "        pairs.append((gt_path, gen_path, rec))\n",
    "        n_usable += 1\n",
    "\n",
    "print(f\"[PAIRING] total_lines={n_total}, usable_pairs={n_usable}, no_target_field={n_no_target}, missing_files={n_missing}\")\n",
    "assert len(pairs) > 0, \"No valid (GT, Generated) pairs found.\"\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2cd1437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DATA] videos_gt=torch.Size([516, 9, 3, 240, 320]), videos_gen=torch.Size([516, 9, 3, 240, 320]), failed_convert=0, TILE_FIT_MODE=tile_gt_to_gen\n"
     ]
    }
   ],
   "source": [
    "# ==== 构建 tensor ====\n",
    "TILE_FIT_MODE   = cfg[\"tile_fit_mode\"]\n",
    "videos_gt_list  = []\n",
    "videos_gen_list = []\n",
    "failed_convert  = 0\n",
    "\n",
    "for gt_path, gen_path, rec in pairs:\n",
    "    try:\n",
    "        v_gt, v_gen = cut_grid_as_video_tilefit(gt_path, gen_path, TILE_FIT_MODE)\n",
    "        if v_gt.shape != v_gen.shape:\n",
    "            failed_convert += 1\n",
    "            continue\n",
    "        videos_gt_list.append(v_gt)\n",
    "        videos_gen_list.append(v_gen)\n",
    "    except Exception:\n",
    "        failed_convert += 1\n",
    "        continue\n",
    "\n",
    "assert len(videos_gt_list) > 0, \"No valid pairs after tile-wise fitting.\"\n",
    "\n",
    "videos_gt  = torch.stack(videos_gt_list,  dim=0)  # [N,9,3,H,W]\n",
    "videos_gen = torch.stack(videos_gen_list, dim=0)\n",
    "\n",
    "N, T, C, H, W = videos_gt.shape\n",
    "print(f\"[DATA] videos_gt={videos_gt.shape}, videos_gen={videos_gen.shape}, failed_convert={failed_convert}, TILE_FIT_MODE={TILE_FIT_MODE}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efbccd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# === 低显存评估：分批上GPU + 混合精度 + FVD自动扩帧 ===\n",
    "\n",
    "# %%\n",
    "import json as pyjson\n",
    "import csv, gc\n",
    "from statistics import mean\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from calculate_mse   import calculate_mse\n",
    "from calculate_fvd   import calculate_fvd\n",
    "from calculate_psnr  import calculate_psnr\n",
    "from calculate_ssim  import calculate_ssim\n",
    "from calculate_lpips import calculate_lpips\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# ====== 可调参数（降显存关键）======\n",
    "GPU_DTYPE   = torch.float16           # fp16 可显著降显存；若报精度错误再换 torch.bfloat16\n",
    "LPIPS_BS    = 1000                       # LPIPS 小批量（按 batch 维拆）\n",
    "FVD_MODE    = \"approx_batch_mean\"     # \"whole\" | \"approx_batch_mean\"\n",
    "FVD_BS      = 50                       # 仅在 approx 模式下生效\n",
    "FVD_MIN_FRM = 10                      # FVD 至少帧数\n",
    "\n",
    "DEVICE = torch.device(cfg[\"device\"])\n",
    "ONLY_FINAL = bool(cfg[\"only_final\"])\n",
    "\n",
    "def _tolist(x):\n",
    "    if hasattr(x, \"tolist\"):\n",
    "        return x.tolist()\n",
    "    return list(x)\n",
    "\n",
    "def last_or_none(seq):\n",
    "    return float(seq[-1]) if len(seq) else None\n",
    "\n",
    "def mean_or_none(seq):\n",
    "    return float(mean(seq)) if len(seq) else None\n",
    "\n",
    "def ensure_min_frames_cpu(videos: torch.Tensor, min_frames=10):\n",
    "    \"\"\"在CPU上扩帧（时间维），避免GPU上扩帧占显存。\"\"\"\n",
    "    if videos.size(1) < min_frames:\n",
    "        t = videos.size(1)\n",
    "        repeat_factor = (min_frames + t - 1) // t\n",
    "        v = videos.repeat(1, repeat_factor, 1, 1, 1)\n",
    "        return v[:, :max(min_frames, t)]\n",
    "    return videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fce3354a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CPU] computing SSIM/PSNR/MSE ...\n",
      "calculate_psnr...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [00:01<00:00, 335.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_mse...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSE (per video): 100%|██████████| 516/516 [00:00<00:00, 2309.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_ssim...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [07:09<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# ---------- 1) SSIM/PSNR/MSE 在 CPU ----------\n",
    "v1_cpu = videos_gt.cpu()\n",
    "v2_cpu = videos_gen.cpu()\n",
    "\n",
    "print(\"[CPU] computing SSIM/PSNR/MSE ...\")\n",
    "\n",
    "psnr_res  = calculate_psnr(v1_cpu, v2_cpu, only_final=ONLY_FINAL)\n",
    "mse_res   = calculate_mse (v1_cpu, v2_cpu, only_final=ONLY_FINAL)\n",
    "ssim_res  = calculate_ssim(v1_cpu, v2_cpu, only_final=ONLY_FINAL)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4afee56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssim_series = _tolist(ssim_res[\"value\"])\n",
    "ssim_std    = _tolist(ssim_res[\"value_std\"])\n",
    "psnr_series = _tolist(psnr_res[\"value\"])\n",
    "psnr_std    = _tolist(psnr_res[\"value_std\"])\n",
    "mse_series  = _tolist(mse_res [\"value\"])\n",
    "mse_std     = _tolist(mse_res [\"value_std\"])\n",
    "\n",
    "# 立刻释放CPU大张量（若内存紧张）\n",
    "del v1_cpu, v2_cpu\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60061272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU] computing LPIPS (batched) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LPIPS (batched):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_lpips...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 516/516 [00:15<00:00, 33.49it/s]\n",
      "                                                              \r"
     ]
    }
   ],
   "source": [
    "# ---------- 2) LPIPS 在 GPU 按 batch 计算 ----------\n",
    "def calc_lpips_batched(v1, v2, bs=4, dtype=torch.float16, device=DEVICE):\n",
    "    vals, stds = [], []\n",
    "    N = v1.size(0)\n",
    "    pbar = tqdm(range(0, N, bs), desc=\"LPIPS (batched)\", leave=False)\n",
    "    for i in pbar:\n",
    "        j = min(i+bs, N)\n",
    "        with torch.autocast(device_type='cuda', dtype=dtype):\n",
    "            out = calculate_lpips(\n",
    "                v1[i:j].to(device, dtype=dtype, non_blocking=True),\n",
    "                v2[i:j].to(device, dtype=dtype, non_blocking=True),\n",
    "                device, only_final=ONLY_FINAL\n",
    "            )\n",
    "        vals.extend(_tolist(out[\"value\"]))\n",
    "        stds.extend(_tolist(out[\"value_std\"]))\n",
    "        # 释放子批内存\n",
    "        del out\n",
    "        torch.cuda.empty_cache()\n",
    "    return {\"value\": vals, \"value_std\": stds}\n",
    "\n",
    "print(\"[GPU] computing LPIPS (batched) ...\")\n",
    "lpips_res = calc_lpips_batched(videos_gt, videos_gen, bs=LPIPS_BS, dtype=GPU_DTYPE, device=DEVICE)\n",
    "lpips_series = _tolist(lpips_res[\"value\"])\n",
    "lpips_std    = _tolist(lpips_res[\"value_std\"])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab891b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU] computing FVD mode = approx_batch_mean ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FVD approx (batched):   0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_fvd...\n",
      "Loading model from: /root/PhotoDoodle/fvd/styleganv/i3d_torchscript.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.37s/it]\n",
      "FVD approx (batched):   9%|▉         | 1/11 [00:04<00:45,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_fvd...\n",
      "Loading model from: /root/PhotoDoodle/fvd/styleganv/i3d_torchscript.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.37s/it]\n",
      "FVD approx (batched):  18%|█▊        | 2/11 [00:11<00:51,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_fvd...\n",
      "Loading model from: /root/PhotoDoodle/fvd/styleganv/i3d_torchscript.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  2.00s/it]\n",
      "FVD approx (batched):  27%|██▋       | 3/11 [00:14<00:36,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_fvd...\n",
      "Loading model from: /root/PhotoDoodle/fvd/styleganv/i3d_torchscript.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.52s/it]\n",
      "FVD approx (batched):  36%|███▋      | 4/11 [00:22<00:40,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_fvd...\n",
      "Loading model from: /root/PhotoDoodle/fvd/styleganv/i3d_torchscript.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n",
      "FVD approx (batched):  45%|████▌     | 5/11 [00:25<00:29,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_fvd...\n",
      "Loading model from: /root/PhotoDoodle/fvd/styleganv/i3d_torchscript.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.59s/it]\n",
      "FVD approx (batched):  55%|█████▍    | 6/11 [00:30<00:24,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_fvd...\n",
      "Loading model from: /root/PhotoDoodle/fvd/styleganv/i3d_torchscript.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.89s/it]\n",
      "FVD approx (batched):  64%|██████▎   | 7/11 [00:36<00:21,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_fvd...\n",
      "Loading model from: /root/PhotoDoodle/fvd/styleganv/i3d_torchscript.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.23s/it]\n",
      "FVD approx (batched):  73%|███████▎  | 8/11 [00:40<00:15,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_fvd...\n",
      "Loading model from: /root/PhotoDoodle/fvd/styleganv/i3d_torchscript.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.03s/it]\n",
      "FVD approx (batched):  82%|████████▏ | 9/11 [00:47<00:10,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_fvd...\n",
      "Loading model from: /root/PhotoDoodle/fvd/styleganv/i3d_torchscript.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.87s/it]\n",
      "FVD approx (batched):  91%|█████████ | 10/11 [00:54<00:05,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_fvd...\n",
      "Loading model from: /root/PhotoDoodle/fvd/styleganv/i3d_torchscript.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.47s/it]\n",
      "                                                                     \r"
     ]
    }
   ],
   "source": [
    "# ---------- 3) FVD 在 GPU：whole 精确 or approx 分批 ----------\n",
    "def calc_fvd_whole(v1, v2, dtype=torch.float16, device=DEVICE):\n",
    "    # 仅一次搬到GPU；先在CPU扩帧，再搬\n",
    "    v1e = ensure_min_frames_cpu(v1, FVD_MIN_FRM).to(device, dtype=dtype, non_blocking=True)\n",
    "    v2e = ensure_min_frames_cpu(v2, FVD_MIN_FRM).to(device, dtype=dtype, non_blocking=True)\n",
    "    with torch.autocast(device_type='cuda', dtype=dtype):\n",
    "        out = calculate_fvd(v1e, v2e, device, method='styleganv', only_final=ONLY_FINAL)\n",
    "    del v1e, v2e\n",
    "    torch.cuda.empty_cache()\n",
    "    return out\n",
    "\n",
    "def calc_fvd_approx_batched(v1, v2, bs=4, dtype=torch.float16, device=DEVICE):\n",
    "    \"\"\"\n",
    "    近似：分批算 FVD，再按批数取平均（严格不等价，但省显存）。\n",
    "    如果你追求严格等价，请改库：先提取全量I3D特征 -> 合并 -> Frechet。\n",
    "    \"\"\"\n",
    "    N = v1.size(0)\n",
    "    vals = []\n",
    "    pbar = tqdm(range(0, N, bs), desc=\"FVD approx (batched)\", leave=False)\n",
    "    for i in pbar:\n",
    "        j = min(i+bs, N)\n",
    "        v1e = ensure_min_frames_cpu(v1[i:j], FVD_MIN_FRM)\n",
    "        v2e = ensure_min_frames_cpu(v2[i:j], FVD_MIN_FRM)\n",
    "        with torch.autocast(device_type='cuda', dtype=dtype):\n",
    "            out = calculate_fvd(\n",
    "                v1e.to(device, dtype=dtype, non_blocking=True),\n",
    "                v2e.to(device, dtype=dtype, non_blocking=True),\n",
    "                device, method='styleganv', only_final=ONLY_FINAL\n",
    "            )\n",
    "        vals.extend(_tolist(out[\"value\"]))\n",
    "        del out, v1e, v2e\n",
    "        torch.cuda.empty_cache()\n",
    "    # 用“最后一个时间点”的批均值代表总体近似\n",
    "    return {\"value\": vals}\n",
    "\n",
    "print(f\"[GPU] computing FVD mode = {FVD_MODE} ...\")\n",
    "if FVD_MODE == \"whole\":\n",
    "    fvd_res = calc_fvd_whole(videos_gt, videos_gen, dtype=GPU_DTYPE, device=DEVICE)\n",
    "else:\n",
    "    fvd_res = calc_fvd_approx_batched(videos_gt, videos_gen, bs=FVD_BS, dtype=GPU_DTYPE, device=DEVICE)\n",
    "\n",
    "fvd_series = _tolist(fvd_res[\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8ba8c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"num_pairs\": 516,\n",
      "  \"video_length\": 9,\n",
      "  \"channels\": 3,\n",
      "  \"height\": 240,\n",
      "  \"width\": 320,\n",
      "  \"tile_fit_mode\": \"tile_gt_to_gen\",\n",
      "  \"only_final\": false,\n",
      "  \"gpu_dtype\": \"float16\",\n",
      "  \"fvd_mode\": \"approx_batch_mean\",\n",
      "  \"fvd_last\": 4095.478073094209,\n",
      "  \"lpips_last\": 0.9942231984563576,\n",
      "  \"psnr_last\": 6.290071680789513,\n",
      "  \"ssim_last\": 0.017831154379311338,\n",
      "  \"mse_last\": 0.21397601068019867,\n",
      "  \"fvd_mean\": 4377.132740365402,\n",
      "  \"lpips_mean\": 0.9391541193118262,\n",
      "  \"psnr_mean\": 7.18772746832456,\n",
      "  \"ssim_mean\": 0.06423100679865956,\n",
      "  \"mse_mean\": 0.17802256014611986\n",
      "}\n",
      "[OK] saved JSON: /root/PhotoDoodle/inference/outputs_bridgeV2_traj_noop/metrics_fit_tile_gt_to_gen_full.json\n",
      "[OK] saved CSV: /root/PhotoDoodle/inference/outputs_bridgeV2_traj_noop/metrics_fit_tile_gt_to_gen_series.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2114"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------- 4) 汇总/保存 ----------\n",
    "N, T, C, H, W = videos_gt.shape\n",
    "summary = {\n",
    "    \"num_pairs\": int(N),\n",
    "    \"video_length\": int(T),\n",
    "    \"channels\": int(C),\n",
    "    \"height\": int(H),\n",
    "    \"width\": int(W),\n",
    "    \"tile_fit_mode\": cfg[\"tile_fit_mode\"],\n",
    "    \"only_final\": ONLY_FINAL,\n",
    "    \"gpu_dtype\": str(GPU_DTYPE).split(\".\")[-1],\n",
    "    \"fvd_mode\": FVD_MODE,\n",
    "\n",
    "    # 最后一帧\n",
    "    \"fvd_last\":   last_or_none(fvd_series),\n",
    "    \"lpips_last\": last_or_none(lpips_series),\n",
    "    \"psnr_last\":  last_or_none(psnr_series),\n",
    "    \"ssim_last\":  last_or_none(ssim_series),\n",
    "    \"mse_last\":   last_or_none(mse_series),\n",
    "\n",
    "    # 均值\n",
    "    \"fvd_mean\":   mean_or_none(fvd_series),\n",
    "    \"lpips_mean\": mean_or_none(lpips_series),\n",
    "    \"psnr_mean\":  mean_or_none(psnr_series),\n",
    "    \"ssim_mean\":  mean_or_none(ssim_series),\n",
    "    \"mse_mean\":   mean_or_none(mse_series),\n",
    "}\n",
    "\n",
    "full_record = {\n",
    "    \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    **summary,\n",
    "    \"series\": {\n",
    "        \"fvd\": fvd_series,\n",
    "        \"lpips\": lpips_series, \"lpips_std\": lpips_std,\n",
    "        \"psnr\": psnr_series,   \"psnr_std\": psnr_std,\n",
    "        \"ssim\": ssim_series,   \"ssim_std\": ssim_std,\n",
    "        \"mse\":  mse_series,    \"mse_std\":  mse_std,\n",
    "    }\n",
    "}\n",
    "\n",
    "print(pyjson.dumps(summary, indent=2))\n",
    "\n",
    "json_path = OUTPUT_DIR / f\"metrics_fit_{cfg['tile_fit_mode']}_full.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(pyjson.dumps(full_record, indent=2))\n",
    "print(f\"[OK] saved JSON: {json_path}\")\n",
    "\n",
    "csv_path = OUTPUT_DIR / f\"metrics_fit_{cfg['tile_fit_mode']}_series.csv\"\n",
    "max_len = max(map(len, [fvd_series, lpips_series, psnr_series, ssim_series, mse_series]))\n",
    "with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    import csv\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"index\",\"fvd\",\"lpips\",\"lpips_std\",\"psnr\",\"psnr_std\",\"ssim\",\"ssim_std\",\"mse\",\"mse_std\"])\n",
    "    for i in range(max_len):\n",
    "        row = [\n",
    "            i,\n",
    "            fvd_series[i]   if i < len(fvd_series)   else \"\",\n",
    "            lpips_series[i] if i < len(lpips_series) else \"\",\n",
    "            lpips_std[i]    if i < len(lpips_std)    else \"\",\n",
    "            psnr_series[i]  if i < len(psnr_series)  else \"\",\n",
    "            psnr_std[i]     if i < len(psnr_std)     else \"\",\n",
    "            ssim_series[i]  if i < len(ssim_series)  else \"\",\n",
    "            ssim_std[i]     if i < len(ssim_std)     else \"\",\n",
    "            mse_series[i]   if i < len(mse_series)   else \"\",\n",
    "            mse_std[i]      if i < len(mse_std)      else \"\",\n",
    "        ]\n",
    "        writer.writerow(row)\n",
    "print(f\"[OK] saved CSV: {csv_path}\")\n",
    "\n",
    "# 显存回收\n",
    "del lpips_res, psnr_res, ssim_res, mse_res, fvd_res\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
