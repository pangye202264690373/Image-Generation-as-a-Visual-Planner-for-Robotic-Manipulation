{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2fb1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # 3×3 Grid 逐块适配评估（Tile-wise Fit, No Global Resize）\n",
    "# - Pairing: results.jsonl 里 ok==True 的样本，使用 output 定位生成图，target/gt 定位 GT 图\n",
    "# - Cutting: 先切 3×3，再逐块适配，顺序 123 / 654 / 789\n",
    "# - Tile Fit Modes:\n",
    "#   * \"tile_strict\":    每块尺寸必须一致，否则跳过\n",
    "#   * \"tile_gen_to_gt\": 生成图每块 -> 适配到 GT 对应块尺寸\n",
    "#   * \"tile_gt_to_gen\": GT 每块     -> 适配到 生成 对应块尺寸\n",
    "# - Metrics:\n",
    "#   * GPU: FVD, LPIPS\n",
    "#   * CPU: SSIM, PSNR, MSE\n",
    "# - Output: 扁平 JSON（含 mse），位于 output_dir\n",
    "\n",
    "# %%\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# ==== 配置 ====\n",
    "CONFIG = {\n",
    "    \"jsonl_path\": \"/root/PhotoDoodle/data/bridge_test/text_test_index.jsonl\",  # 原始输入 JSONL（含 target/gt 相对路径）\n",
    "    \"output_dir\": \"inference/outputs_bridgeV2_text\",                            # 推理输出目录（含 results.jsonl）\n",
    "    \"tile_fit_mode\": \"tile_gen_to_gt\",  # \"tile_strict\" | \"tile_gen_to_gt\" | \"tile_gt_to_gen\"\n",
    "    \"device\": \"cpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"only_final\": False,                # True: 指标只比较最后一帧\n",
    "}\n",
    "\n",
    "# ==== 你已有的指标脚本（需可导入） ====\n",
    "from calculate_fvd import calculate_fvd\n",
    "from calculate_psnr import calculate_psnr\n",
    "from calculate_ssim import calculate_ssim\n",
    "from calculate_lpips import calculate_lpips\n",
    "from calculate_mse import calculate_mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9461e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 工具函数：路径解析、切 3×3（蛇形顺序）、逐块适配\n",
    "\n",
    "# %%\n",
    "def resolve_path_maybe_relative(p: str, base: Path) -> Path:\n",
    "    \"\"\"相对路径基于 base；绝对路径原样返回。\"\"\"\n",
    "    pp = Path(p)\n",
    "    return pp if pp.is_absolute() else (base / pp).resolve()\n",
    "\n",
    "def _grid_splits(length: int) -> List[int]:\n",
    "    \"\"\"\n",
    "    用 linspace 生成分割边界（0..length），四个边界 -> 三段。\n",
    "    即使 length 不是 3 的倍数，也无缝覆盖且不重叠。\n",
    "    \"\"\"\n",
    "    edges = np.linspace(0, length, 4)\n",
    "    return [int(round(x)) for x in edges]\n",
    "\n",
    "def _cut_3x3_tiles(im: Image.Image) -> List[Image.Image]:\n",
    "    \"\"\"按 3×3 切成 9 个 PIL.Image，蛇形顺序：123 / 654 / 789。\"\"\"\n",
    "    W, H = im.size\n",
    "    xs = _grid_splits(W)  # [x0,x1,x2,x3]\n",
    "    ys = _grid_splits(H)  # [y0,y1,y2,y3]\n",
    "    # 线性顺序的 9 个 box（行优先）\n",
    "    boxes_linear = [(xs[c], ys[r], xs[c+1], ys[r+1]) for r in range(3) for c in range(3)]\n",
    "    # 蛇形顺序映射\n",
    "    order = [0, 1, 2, 5, 4, 3, 6, 7, 8]\n",
    "    return [im.crop(boxes_linear[idx]) for idx in order]\n",
    "\n",
    "def _tile_sizes(tiles: List[Image.Image]) -> List[Tuple[int,int]]:\n",
    "    return [t.size for t in tiles]  # (W,H)\n",
    "\n",
    "def _resize_tiles_to(tiles: List[Image.Image], target_sizes: List[Tuple[int,int]]) -> List[Image.Image]:\n",
    "    \"\"\"将 tiles 逐块 resize 到 target_sizes（(W,H) 列表）。\"\"\"\n",
    "    out = []\n",
    "    for t, (tw, th) in zip(tiles, target_sizes):\n",
    "        out.append(t if t.size == (tw, th) else t.resize((tw, th), Image.BICUBIC))\n",
    "    return out\n",
    "\n",
    "def _tiles_to_tensor(tiles: List[Image.Image]) -> torch.Tensor:\n",
    "    \"\"\"9 个 RGB PIL tile -> [T=9, C=3, H, W]，像素∈[0,1]。\"\"\"\n",
    "    frames = []\n",
    "    for t in tiles:\n",
    "        arr = np.asarray(t, dtype=np.uint8)\n",
    "        ten = torch.from_numpy(arr).permute(2, 0, 1).float() / 255.0\n",
    "        frames.append(ten)\n",
    "    return torch.stack(frames, dim=0)\n",
    "\n",
    "def cut_grid_as_video_tilefit(gt_path: Path, gen_path: Path, tile_fit_mode: str) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    返回 (v_gt, v_gen)：\n",
    "      1) 各自切 3×3 -> 9 tiles（蛇形）\n",
    "      2) 逐块适配（避免整图 resize 造成跨格模糊）\n",
    "      3) 各自拼成 [9,3,H,W]\n",
    "    \"\"\"\n",
    "    gt_im  = Image.open(gt_path).convert(\"RGB\")\n",
    "    gen_im = Image.open(gen_path).convert(\"RGB\")\n",
    "\n",
    "    gt_tiles  = _cut_3x3_tiles(gt_im)    # [9]\n",
    "    gen_tiles = _cut_3x3_tiles(gen_im)   # [9]\n",
    "\n",
    "    if tile_fit_mode == \"tile_strict\":\n",
    "        if _tile_sizes(gt_tiles) != _tile_sizes(gen_tiles):\n",
    "            gt_im.close(); gen_im.close()\n",
    "            raise AssertionError(f\"[tile_strict] per-tile sizes mismatch: GT={_tile_sizes(gt_tiles)} vs GEN={_tile_sizes(gen_tiles)}\")\n",
    "\n",
    "    elif tile_fit_mode == \"tile_gen_to_gt\":\n",
    "        target_sizes = _tile_sizes(gt_tiles)\n",
    "        gen_tiles = _resize_tiles_to(gen_tiles, target_sizes)\n",
    "\n",
    "    elif tile_fit_mode == \"tile_gt_to_gen\":\n",
    "        target_sizes = _tile_sizes(gen_tiles)\n",
    "        gt_tiles = _resize_tiles_to(gt_tiles, target_sizes)\n",
    "\n",
    "    else:\n",
    "        gt_im.close(); gen_im.close()\n",
    "        raise ValueError(f\"Unknown tile_fit_mode: {tile_fit_mode}\")\n",
    "\n",
    "    v_gt  = _tiles_to_tensor(gt_tiles)    # [9,3,H,W]\n",
    "    v_gen = _tiles_to_tensor(gen_tiles)   # [9,3,H,W]\n",
    "\n",
    "    gt_im.close(); gen_im.close()\n",
    "    return v_gt, v_gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02944803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Pairing：从 results.jsonl 配对 GT 与生成图\n",
    "\n",
    "# %%\n",
    "cfg = CONFIG\n",
    "JSONL_PATH   = Path(cfg[\"jsonl_path\"]).resolve()\n",
    "JSONL_BASE   = JSONL_PATH.parent\n",
    "OUTPUT_DIR   = Path(cfg[\"output_dir\"]).resolve()\n",
    "RESULTS_PATH = OUTPUT_DIR / \"results.jsonl\"\n",
    "\n",
    "pairs: List[Tuple[Path, Path, dict]] = []\n",
    "n_total = n_usable = n_no_target = n_missing = 0\n",
    "\n",
    "assert RESULTS_PATH.exists(), f\"results.jsonl not found: {RESULTS_PATH}\"\n",
    "with open(RESULTS_PATH, \"r\", encoding=\"utf-8\") as fr:\n",
    "    for line in fr:\n",
    "        n_total += 1\n",
    "        try:\n",
    "            rec = json.loads(line)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if not rec.get(\"ok\", False):\n",
    "            continue\n",
    "\n",
    "        out_rel = rec.get(\"output\")\n",
    "        if not out_rel:\n",
    "            continue\n",
    "        gen_path = (OUTPUT_DIR / out_rel).resolve()\n",
    "\n",
    "        gt_raw = rec.get(\"target\") or rec.get(\"gt\")\n",
    "        if not gt_raw:\n",
    "            n_no_target += 1\n",
    "            continue\n",
    "        gt_path = resolve_path_maybe_relative(gt_raw, JSONL_BASE)\n",
    "\n",
    "        if not (gen_path.exists() and gt_path.exists()):\n",
    "            n_missing += 1\n",
    "            continue\n",
    "\n",
    "        pairs.append((gt_path, gen_path, rec))\n",
    "        n_usable += 1\n",
    "\n",
    "print(f\"[PAIRING] total_lines={n_total}, usable_pairs={n_usable}, \"\n",
    "      f\"no_target_field={n_no_target}, missing_files={n_missing}\")\n",
    "assert len(pairs) > 0, \"No valid (GT, Generated) pairs found.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b674589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 构建 [N, 9, 3, H, W] 张量（逐块适配）\n",
    "\n",
    "# %%\n",
    "TILE_FIT_MODE = cfg[\"tile_fit_mode\"]\n",
    "videos_gt_list, videos_gen_list = [], []\n",
    "failed_convert = 0\n",
    "\n",
    "for gt_path, gen_path, rec in pairs:\n",
    "    try:\n",
    "        v_gt, v_gen = cut_grid_as_video_tilefit(gt_path, gen_path, TILE_FIT_MODE)\n",
    "        # 能 stack：最终两者形状需要一致\n",
    "        if v_gt.shape != v_gen.shape:\n",
    "            failed_convert += 1\n",
    "            continue\n",
    "        videos_gt_list.append(v_gt)\n",
    "        videos_gen_list.append(v_gen)\n",
    "    except Exception:\n",
    "        failed_convert += 1\n",
    "        continue\n",
    "\n",
    "assert len(videos_gt_list) > 0, \"No valid pairs after tile-wise fitting.\"\n",
    "\n",
    "videos_gt  = torch.stack(videos_gt_list,  dim=0)  # [N,9,3,H,W]\n",
    "videos_gen = torch.stack(videos_gen_list, dim=0)  # [N,9,3,H,W]\n",
    "N, T, C, H, W = videos_gt.shape\n",
    "print(f\"[DATA] videos_gt={videos_gt.shape}, videos_gen={videos_gen.shape}, \"\n",
    "      f\"failed_convert={failed_convert}, TILE_FIT_MODE={TILE_FIT_MODE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14bba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 计算指标：GPU(FVD/LPIPS) + CPU(SSIM/PSNR/MSE)，并扁平化保存\n",
    "\n",
    "# %%\n",
    "DEVICE = torch.device(cfg[\"device\"])\n",
    "ONLY_FINAL = bool(cfg[\"only_final\"])\n",
    "\n",
    "# GPU（FVD/LPIPS）\n",
    "v1_gpu = videos_gt.to(DEVICE, non_blocking=True)\n",
    "v2_gpu = videos_gen.to(DEVICE, non_blocking=True)\n",
    "\n",
    "# CPU（SSIM/PSNR/MSE —— 兼容 numpy）\n",
    "v1_cpu = videos_gt.cpu()\n",
    "v2_cpu = videos_gen.cpu()\n",
    "\n",
    "metrics = {}\n",
    "# GPU-heavy\n",
    "metrics[\"fvd\"]   = float(calculate_fvd(v1_gpu, v2_gpu, DEVICE, method='styleganv', only_final=ONLY_FINAL))\n",
    "metrics[\"lpips\"] = float(calculate_lpips(v1_gpu, v2_gpu, DEVICE, only_final=ONLY_FINAL))\n",
    "# CPU / numpy\n",
    "metrics[\"ssim\"]  = float(calculate_ssim(v1_cpu, v2_cpu, only_final=ONLY_FINAL))\n",
    "metrics[\"psnr\"]  = float(calculate_psnr(v1_cpu, v2_cpu, only_final=ONLY_FINAL))\n",
    "metrics[\"mse\"]   = float(calculate_mse(v1_cpu, v2_cpu, only_final=ONLY_FINAL))\n",
    "\n",
    "flat_record = {\n",
    "    \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"tile_fit_mode\": TILE_FIT_MODE,\n",
    "    \"only_final\": ONLY_FINAL,\n",
    "    \"num_pairs\": int(N),\n",
    "    \"video_length\": int(T),\n",
    "    \"channels\": int(C),\n",
    "    \"height\": int(H),\n",
    "    \"width\": int(W),\n",
    "    # 扁平指标\n",
    "    **metrics,\n",
    "}\n",
    "\n",
    "print(json.dumps(flat_record, indent=2))\n",
    "\n",
    "out_path = OUTPUT_DIR / f\"metrics_fit_{TILE_FIT_MODE}_flat.json\"\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(flat_record, indent=2))\n",
    "print(f\"[OK] flattened metrics saved to: {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
